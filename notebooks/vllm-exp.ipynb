{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from vllm import EngineArgs, LLMEngine, RequestOutput, SamplingParams\n",
    "from vllm.lora.request import LoRARequest\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This example shows how to use the multi-LoRA functionality\n",
    "for offline inference.\n",
    "\n",
    "Requires HuggingFace credentials for access to Llama2.\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from vllm import EngineArgs, LLMEngine, RequestOutput, SamplingParams\n",
    "from vllm.lora.request import LoRARequest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_test_prompts(\n",
    "        lora_path: str\n",
    ") -> List[Tuple[str, SamplingParams, Optional[LoRARequest]]]:\n",
    "    \"\"\"Create a list of test prompts with their sampling parameters.\n",
    "\n",
    "    2 requests for base model, 4 requests for the LoRA. We define 2\n",
    "    different LoRA adapters (using the same model for demo purposes).\n",
    "    Since we also set `max_loras=1`, the expectation is that the requests\n",
    "    with the second LoRA adapter will be ran after all requests with the\n",
    "    first adapter have finished.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        (\"A robot may not injure a human being\",\n",
    "         SamplingParams(temperature=0.0,\n",
    "                        logprobs=1,\n",
    "                        prompt_logprobs=1,\n",
    "                        max_tokens=128), None),\n",
    "        (\"To be or not to be,\",\n",
    "         SamplingParams(temperature=0.8,\n",
    "                        top_k=5,\n",
    "                        presence_penalty=0.2,\n",
    "                        max_tokens=128), None),\n",
    "        (\n",
    "            \"[user] Write a SQL query to answer the question based on the table schema.\\n\\n context: CREATE TABLE table_name_74 (icao VARCHAR, airport VARCHAR)\\n\\n question: Name the ICAO for lilongwe international airport [/user] [assistant]\",  # noqa: E501\n",
    "            SamplingParams(temperature=0.0,\n",
    "                           logprobs=1,\n",
    "                           prompt_logprobs=1,\n",
    "                           max_tokens=128,\n",
    "                           stop_token_ids=[32003]),\n",
    "            LoRARequest(\"sql-lora\", 1, lora_path)),\n",
    "        (\n",
    "            \"[user] Write a SQL query to answer the question based on the table schema.\\n\\n context: CREATE TABLE table_name_11 (nationality VARCHAR, elector VARCHAR)\\n\\n question: When Anchero Pantaleone was the elector what is under nationality? [/user] [assistant]\",  # noqa: E501\n",
    "            SamplingParams(n=3,\n",
    "                           best_of=3,\n",
    "                           use_beam_search=True,\n",
    "                           temperature=0,\n",
    "                           max_tokens=128,\n",
    "                           stop_token_ids=[32003]),\n",
    "            LoRARequest(\"sql-lora\", 1, lora_path)),\n",
    "        (\n",
    "            \"[user] Write a SQL query to answer the question based on the table schema.\\n\\n context: CREATE TABLE table_name_74 (icao VARCHAR, airport VARCHAR)\\n\\n question: Name the ICAO for lilongwe international airport [/user] [assistant]\",  # noqa: E501\n",
    "            SamplingParams(temperature=0.0,\n",
    "                           logprobs=1,\n",
    "                           prompt_logprobs=1,\n",
    "                           max_tokens=128,\n",
    "                           stop_token_ids=[32003]),\n",
    "            LoRARequest(\"sql-lora2\", 2, lora_path)),\n",
    "        (\n",
    "            \"[user] Write a SQL query to answer the question based on the table schema.\\n\\n context: CREATE TABLE table_name_11 (nationality VARCHAR, elector VARCHAR)\\n\\n question: When Anchero Pantaleone was the elector what is under nationality? [/user] [assistant]\",  # noqa: E501\n",
    "            SamplingParams(n=3,\n",
    "                           best_of=3,\n",
    "                           use_beam_search=True,\n",
    "                           temperature=0,\n",
    "                           max_tokens=128,\n",
    "                           stop_token_ids=[32003]),\n",
    "            LoRARequest(\"sql-lora\", 1, lora_path)),\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-09 22:11:53 llm_engine.py:161] Initializing an LLM engine (v0.4.3) with config: model='meta-llama/Llama-2-7b-hf', speculative_config=None, tokenizer='meta-llama/Llama-2-7b-hf', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=meta-llama/Llama-2-7b-hf)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harpreet_guest2/akshat/Multi-Lora/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-09 22:11:54 weight_utils.py:207] Using model weights format ['*.safetensors']\n",
      "INFO 06-09 22:11:56 model_runner.py:146] Loading model weights took 12.5562 GB\n",
      "INFO 06-09 22:11:57 gpu_executor.py:83] # GPU blocks: 3786, # CPU blocks: 512\n",
      "INFO 06-09 22:11:59 model_runner.py:854] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 06-09 22:11:59 model_runner.py:858] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 06-09 22:12:03 model_runner.py:924] Graph capturing finished in 4 secs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f7d7ddcb7e4ced822d087c5dbb4a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RequestOutput(request_id=2, prompt='[user] Write a SQL query to answer the question based on the table schema.\\n\\n context: CREATE TABLE table_name_74 (icao VARCHAR, airport VARCHAR)\\n\\n question: Name the ICAO for lilongwe international airport [/user] [assistant]', prompt_token_ids=[1, 32000, 29871, 14350, 263, 3758, 2346, 304, 1234, 278, 1139, 2729, 373, 278, 1591, 10938, 29889, 13, 13, 3030, 29901, 14602, 10911, 1591, 29918, 978, 29918, 29955, 29946, 313, 983, 29877, 21748, 29892, 4799, 637, 21748, 29897, 13, 13, 1139, 29901, 4408, 278, 306, 5454, 29949, 363, 301, 309, 549, 705, 6121, 4799, 637, 29871, 32001, 259, 32002], prompt_logprobs=[None, {32000: Logprob(logprob=-0.004810901824384928, rank=1, decoded_token='[user]')}, {29871: Logprob(logprob=-0.12253902107477188, rank=1, decoded_token='')}, {14350: Logprob(logprob=-0.0002803409588523209, rank=1, decoded_token='Write')}, {263: Logprob(logprob=-0.0004917366313748062, rank=1, decoded_token='a')}, {3758: Logprob(logprob=-0.0004319211875554174, rank=1, decoded_token='SQL')}, {2346: Logprob(logprob=-0.0005189026123844087, rank=1, decoded_token='query')}, {304: Logprob(logprob=-0.00041940953815355897, rank=1, decoded_token='to')}, {1234: Logprob(logprob=-0.00020001317898277193, rank=1, decoded_token='answer')}, {278: Logprob(logprob=-0.00045658653834834695, rank=1, decoded_token='the')}, {1139: Logprob(logprob=-0.0006170752458274364, rank=1, decoded_token='question')}, {2729: Logprob(logprob=-0.0004844683862756938, rank=1, decoded_token='based')}, {373: Logprob(logprob=-0.0006945105269551277, rank=1, decoded_token='on')}, {278: Logprob(logprob=-2.3007127310847864e-05, rank=1, decoded_token='the')}, {1591: Logprob(logprob=-0.00047672350774519145, rank=1, decoded_token='table')}, {10938: Logprob(logprob=-0.0010026433737948537, rank=1, decoded_token='schema')}, {29889: Logprob(logprob=-0.0014340127818286419, rank=1, decoded_token='.')}, {13: Logprob(logprob=-0.004083035048097372, rank=1, decoded_token='\\n')}, {13: Logprob(logprob=-0.000774798565544188, rank=1, decoded_token='\\n')}, {3030: Logprob(logprob=-0.001105412608012557, rank=1, decoded_token=' context')}, {29901: Logprob(logprob=-3.349725011503324e-05, rank=1, decoded_token='\\n:')}, {14602: Logprob(logprob=-0.00024256148026324809, rank=1, decoded_token='\\n\\n CREATE')}, {10911: Logprob(logprob=-0.0005957497633062303, rank=1, decoded_token='\\n\\n\\n TABLE')}, {1591: Logprob(logprob=-0.07258503884077072, rank=1, decoded_token='\\n\\n\\n\\n table')}, {29918: Logprob(logprob=-0.0006317288498394191, rank=1, decoded_token='\\n\\n\\n\\n\\n_')}, {978: Logprob(logprob=-0.3755280077457428, rank=1, decoded_token='\\n\\n\\n\\n\\n\\nname')}, {29918: Logprob(logprob=-0.0005237876321189106, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n_')}, {29955: Logprob(logprob=-2.1367220878601074, rank=3, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n7'), 29953: Logprob(logprob=-2.1054720878601074, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n6')}, {29946: Logprob(logprob=-2.3930678367614746, rank=6, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n4'), 29896: Logprob(logprob=-2.2368178367614746, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n1')}, {313: Logprob(logprob=-0.0012511529494076967, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n (')}, {983: Logprob(logprob=-11.944221496582031, rank=3308, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nica'), 1256: Logprob(logprob=-3.170783758163452, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ndate')}, {29877: Logprob(logprob=-0.08102887123823166, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\no')}, {21748: Logprob(logprob=-0.6854418516159058, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n VARCHAR')}, {29892: Logprob(logprob=-0.005799727980047464, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n,')}, {4799: Logprob(logprob=-2.178102493286133, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n air')}, {637: Logprob(logprob=-1.936806321144104, rank=2, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nport'), 1220: Logprob(logprob=-0.2414938360452652, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nline')}, {21748: Logprob(logprob=-0.4293473958969116, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n VARCHAR')}, {29897: Logprob(logprob=-0.1584867238998413, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n)')}, {13: Logprob(logprob=-0.002474462613463402, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')}, {13: Logprob(logprob=-0.00011824862303910777, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')}, {1139: Logprob(logprob=-7.73638384998776e-05, rank=1, decoded_token=' question')}, {29901: Logprob(logprob=-0.00013219437096267939, rank=1, decoded_token='\\n:')}, {4408: Logprob(logprob=-2.1940650939941406, rank=3, decoded_token='\\n\\n Name'), 1724: Logprob(logprob=-0.6471899747848511, rank=1, decoded_token='\\n\\n What')}, {278: Logprob(logprob=-0.21818111836910248, rank=1, decoded_token='\\n\\n\\n the')}, {306: Logprob(logprob=-0.9201486110687256, rank=2, decoded_token='\\n\\n\\n\\n I'), 29871: Logprob(logprob=-0.8810861110687256, rank=1, decoded_token='\\n\\n\\n\\n ')}, {5454: Logprob(logprob=-0.07014685124158859, rank=1, decoded_token='\\n\\n\\n\\n\\nCA')}, {29949: Logprob(logprob=-0.0022903657518327236, rank=1, decoded_token='\\n\\n\\n\\n\\n\\nO')}, {363: Logprob(logprob=-1.1083241701126099, rank=2, decoded_token='\\n\\n\\n\\n\\n\\n\\n for'), 310: Logprob(logprob=-1.1005116701126099, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n of')}, {301: Logprob(logprob=-6.23159122467041, rank=51, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n l'), 278: Logprob(logprob=-1.204247236251831, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n the')}, {309: Logprob(logprob=-4.745607376098633, rank=20, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\nil'), 898: Logprob(logprob=-2.136232376098633, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\nond')}, {549: Logprob(logprob=-0.7052613496780396, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nong')}, {705: Logprob(logprob=-0.002821514382958412, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nwe')}, {6121: Logprob(logprob=-1.5109386444091797, rank=2, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n international'), 4799: Logprob(logprob=-1.2375011444091797, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n air')}, {4799: Logprob(logprob=-0.1420583575963974, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n air')}, {637: Logprob(logprob=-0.0024986020289361477, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nport')}, {29871: Logprob(logprob=-0.4706132113933563, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n ')}, {32001: Logprob(logprob=-0.0058407350443303585, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[/user]')}, {259: Logprob(logprob=-0.0001110968878492713, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  ')}, {32002: Logprob(logprob=-0.0002335037279408425, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[assistant]')}], outputs=[CompletionOutput(index=0, text=\"  SELECT icao FROM table_name_74 WHERE airport = 'lilongwe international airport' \", token_ids=[29871, 5097, 474, 1113, 29877, 3895, 1591, 29918, 978, 29918, 29955, 29946, 5754, 4799, 637, 353, 525, 29880, 309, 549, 705, 6121, 4799, 637, 29915, 29871, 32003], cumulative_logprob=-1.4475092418086888, logprobs=[{29871: Logprob(logprob=-1.6093124941107817e-05, rank=1, decoded_token=' ')}, {5097: Logprob(logprob=-0.0011726891389116645, rank=1, decoded_token=' SELECT')}, {474: Logprob(logprob=-1.063267469406128, rank=1, decoded_token=' i')}, {1113: Logprob(logprob=-0.08770003914833069, rank=1, decoded_token='ca')}, {29877: Logprob(logprob=-1.3232143828645349e-05, rank=1, decoded_token='o')}, {3895: Logprob(logprob=-0.006226189900189638, rank=1, decoded_token=' FROM')}, {1591: Logprob(logprob=-0.0008002892718650401, rank=1, decoded_token=' table')}, {29918: Logprob(logprob=-1.4305104514278355e-06, rank=1, decoded_token='_')}, {978: Logprob(logprob=-9.023735765367746e-05, rank=1, decoded_token='name')}, {29918: Logprob(logprob=-6.437280717364047e-06, rank=1, decoded_token='_')}, {29955: Logprob(logprob=-0.00013839241000823677, rank=1, decoded_token='7')}, {29946: Logprob(logprob=-8.546940807718784e-05, rank=1, decoded_token='4')}, {5754: Logprob(logprob=-0.0008442413527518511, rank=1, decoded_token=' WHERE')}, {4799: Logprob(logprob=-0.004047061316668987, rank=1, decoded_token=' air')}, {637: Logprob(logprob=-4.1960789531003684e-05, rank=1, decoded_token='port')}, {353: Logprob(logprob=-0.003187221009284258, rank=1, decoded_token=' =')}, {525: Logprob(logprob=-0.002795361913740635, rank=1, decoded_token=\" '\")}, {29880: Logprob(logprob=-0.19404155015945435, rank=1, decoded_token='l')}, {309: Logprob(logprob=-0.0003323002893012017, rank=1, decoded_token='il')}, {549: Logprob(logprob=-4.851700214203447e-05, rank=1, decoded_token='ong')}, {705: Logprob(logprob=-0.0003953390696551651, rank=1, decoded_token='we')}, {6121: Logprob(logprob=-0.003171654185280204, rank=1, decoded_token=' international')}, {4799: Logprob(logprob=-0.07272005826234818, rank=1, decoded_token=' air')}, {637: Logprob(logprob=-0.00010144196130568162, rank=1, decoded_token='port')}, {29915: Logprob(logprob=-0.0049329716712236404, rank=1, decoded_token=\"'\")}, {29871: Logprob(logprob=-0.0005791893927380443, rank=1, decoded_token=' ')}, {32003: Logprob(logprob=-0.0007524043321609497, rank=1, decoded_token='[/assistant]')}], finish_reason=stop, stop_reason=32003)], finished=True, metrics=RequestMetrics(arrival_time=1717989123.2752287, last_token_time=1717989124.1965003, first_scheduled_time=1717989123.3321383, first_token_time=1717989123.3975146, time_in_queue=0.05690956115722656, finished_time=1717989124.1964715), lora_request=LoRARequest(lora_name='sql-lora', lora_int_id=1, lora_local_path='/home/harpreet_guest2/.cache/huggingface/hub/models--yard1--llama-2-7b-sql-lora-test/snapshots/0dfa347e8877a4d4ed19ee56c140fa518470028c', long_lora_max_len=None))\n",
      "RequestOutput(request_id=3, prompt='[user] Write a SQL query to answer the question based on the table schema.\\n\\n context: CREATE TABLE table_name_11 (nationality VARCHAR, elector VARCHAR)\\n\\n question: When Anchero Pantaleone was the elector what is under nationality? [/user] [assistant]', prompt_token_ids=[1, 32000, 29871, 14350, 263, 3758, 2346, 304, 1234, 278, 1139, 2729, 373, 278, 1591, 10938, 29889, 13, 13, 3030, 29901, 14602, 10911, 1591, 29918, 978, 29918, 29896, 29896, 313, 29876, 1288, 537, 21748, 29892, 3546, 272, 21748, 29897, 13, 13, 1139, 29901, 1932, 530, 305, 1489, 349, 424, 744, 650, 471, 278, 3546, 272, 825, 338, 1090, 4797, 537, 29973, 29871, 32001, 259, 32002], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"  SELECT nationality FROM table_name_11 WHERE elector = 'anchero pantaleone' \", token_ids=[29871, 5097, 4797, 537, 3895, 1591, 29918, 978, 29918, 29896, 29896, 5754, 3546, 272, 353, 525, 14588, 1489, 282, 424, 744, 650, 29915, 29871, 32003], cumulative_logprob=-0.8868117344870825, logprobs=None, finish_reason=stop, stop_reason=32003), CompletionOutput(index=1, text=\"  SELECT nationality FROM table_name_11 WHERE elector = 'Anchero Pantaleone' \", token_ids=[29871, 5097, 4797, 537, 3895, 1591, 29918, 978, 29918, 29896, 29896, 5754, 3546, 272, 353, 525, 2744, 305, 1489, 349, 424, 744, 650, 29915, 29871, 32003], cumulative_logprob=-0.9184906315756507, logprobs=None, finish_reason=stop, stop_reason=32003), CompletionOutput(index=2, text=\"  SELECT nationality FROM table_name_11 WHERE elector = 'ANCHERO PANTALEONE' \", token_ids=[29871, 5097, 4797, 537, 3895, 1591, 29918, 978, 29918, 29896, 29896, 5754, 3546, 272, 353, 525, 2190, 3210, 1001, 29949, 349, 2190, 6040, 1307, 12413, 29915, 29871, 32003], cumulative_logprob=-3.71456190423919, logprobs=None, finish_reason=stop, stop_reason=32003)], finished=True, metrics=RequestMetrics(arrival_time=1717989123.3982873, last_token_time=1717989124.223541, first_scheduled_time=1717989123.3987072, first_token_time=1717989123.4288049, time_in_queue=0.00041985511779785156, finished_time=1717989124.223526), lora_request=LoRARequest(lora_name='sql-lora', lora_int_id=1, lora_local_path='/home/harpreet_guest2/.cache/huggingface/hub/models--yard1--llama-2-7b-sql-lora-test/snapshots/0dfa347e8877a4d4ed19ee56c140fa518470028c', long_lora_max_len=None))\n",
      "RequestOutput(request_id=5, prompt='[user] Write a SQL query to answer the question based on the table schema.\\n\\n context: CREATE TABLE table_name_11 (nationality VARCHAR, elector VARCHAR)\\n\\n question: When Anchero Pantaleone was the elector what is under nationality? [/user] [assistant]', prompt_token_ids=[1, 32000, 29871, 14350, 263, 3758, 2346, 304, 1234, 278, 1139, 2729, 373, 278, 1591, 10938, 29889, 13, 13, 3030, 29901, 14602, 10911, 1591, 29918, 978, 29918, 29896, 29896, 313, 29876, 1288, 537, 21748, 29892, 3546, 272, 21748, 29897, 13, 13, 1139, 29901, 1932, 530, 305, 1489, 349, 424, 744, 650, 471, 278, 3546, 272, 825, 338, 1090, 4797, 537, 29973, 29871, 32001, 259, 32002], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"  SELECT nationality FROM table_name_11 WHERE elector = 'anchero pantaleone' \", token_ids=[29871, 5097, 4797, 537, 3895, 1591, 29918, 978, 29918, 29896, 29896, 5754, 3546, 272, 353, 525, 14588, 1489, 282, 424, 744, 650, 29915, 29871, 32003], cumulative_logprob=-0.887103857392276, logprobs=None, finish_reason=stop, stop_reason=32003), CompletionOutput(index=1, text=\"  SELECT nationality FROM table_name_11 WHERE elector = 'Anchero Pantaleone' \", token_ids=[29871, 5097, 4797, 537, 3895, 1591, 29918, 978, 29918, 29896, 29896, 5754, 3546, 272, 353, 525, 2744, 305, 1489, 349, 424, 744, 650, 29915, 29871, 32003], cumulative_logprob=-0.9189916047978386, logprobs=None, finish_reason=stop, stop_reason=32003), CompletionOutput(index=2, text=\"  SELECT nationality FROM table_name_11 WHERE elector = 'ANCHERO PANTALEONE' \", token_ids=[29871, 5097, 4797, 537, 3895, 1591, 29918, 978, 29918, 29896, 29896, 5754, 3546, 272, 353, 525, 2190, 3210, 1001, 29949, 349, 2190, 6040, 1307, 12413, 29915, 29871, 32003], cumulative_logprob=-3.722703339073405, logprobs=None, finish_reason=stop, stop_reason=32003)], finished=True, metrics=RequestMetrics(arrival_time=1717989123.5101101, last_token_time=1717989124.248533, first_scheduled_time=1717989123.510349, first_token_time=1717989123.5399637, time_in_queue=0.00023889541625976562, finished_time=1717989124.2485304), lora_request=LoRARequest(lora_name='sql-lora', lora_int_id=1, lora_local_path='/home/harpreet_guest2/.cache/huggingface/hub/models--yard1--llama-2-7b-sql-lora-test/snapshots/0dfa347e8877a4d4ed19ee56c140fa518470028c', long_lora_max_len=None))\n",
      "RequestOutput(request_id=4, prompt='[user] Write a SQL query to answer the question based on the table schema.\\n\\n context: CREATE TABLE table_name_74 (icao VARCHAR, airport VARCHAR)\\n\\n question: Name the ICAO for lilongwe international airport [/user] [assistant]', prompt_token_ids=[1, 32000, 29871, 14350, 263, 3758, 2346, 304, 1234, 278, 1139, 2729, 373, 278, 1591, 10938, 29889, 13, 13, 3030, 29901, 14602, 10911, 1591, 29918, 978, 29918, 29955, 29946, 313, 983, 29877, 21748, 29892, 4799, 637, 21748, 29897, 13, 13, 1139, 29901, 4408, 278, 306, 5454, 29949, 363, 301, 309, 549, 705, 6121, 4799, 637, 29871, 32001, 259, 32002], prompt_logprobs=[None, {32000: Logprob(logprob=-0.004810901824384928, rank=1, decoded_token='[user]')}, {29871: Logprob(logprob=-0.12253902107477188, rank=1, decoded_token='')}, {14350: Logprob(logprob=-0.0002803409588523209, rank=1, decoded_token='Write')}, {263: Logprob(logprob=-0.0004917366313748062, rank=1, decoded_token='a')}, {3758: Logprob(logprob=-0.0004319211875554174, rank=1, decoded_token='SQL')}, {2346: Logprob(logprob=-0.0005189026123844087, rank=1, decoded_token='query')}, {304: Logprob(logprob=-0.00041940953815355897, rank=1, decoded_token='to')}, {1234: Logprob(logprob=-0.00020001317898277193, rank=1, decoded_token='answer')}, {278: Logprob(logprob=-0.00045658653834834695, rank=1, decoded_token='the')}, {1139: Logprob(logprob=-0.0006170752458274364, rank=1, decoded_token='question')}, {2729: Logprob(logprob=-0.0004844683862756938, rank=1, decoded_token='based')}, {373: Logprob(logprob=-0.0006945105269551277, rank=1, decoded_token='on')}, {278: Logprob(logprob=-2.3007127310847864e-05, rank=1, decoded_token='the')}, {1591: Logprob(logprob=-0.00047672350774519145, rank=1, decoded_token='table')}, {10938: Logprob(logprob=-0.0010026433737948537, rank=1, decoded_token='schema')}, {29889: Logprob(logprob=-0.0014340127818286419, rank=1, decoded_token='.')}, {13: Logprob(logprob=-0.004083035048097372, rank=1, decoded_token='\\n')}, {13: Logprob(logprob=-0.000774798565544188, rank=1, decoded_token='\\n')}, {3030: Logprob(logprob=-0.001105412608012557, rank=1, decoded_token=' context')}, {29901: Logprob(logprob=-3.349725011503324e-05, rank=1, decoded_token='\\n:')}, {14602: Logprob(logprob=-0.00024256148026324809, rank=1, decoded_token='\\n\\n CREATE')}, {10911: Logprob(logprob=-0.0005957497633062303, rank=1, decoded_token='\\n\\n\\n TABLE')}, {1591: Logprob(logprob=-0.07258503884077072, rank=1, decoded_token='\\n\\n\\n\\n table')}, {29918: Logprob(logprob=-0.0006317288498394191, rank=1, decoded_token='\\n\\n\\n\\n\\n_')}, {978: Logprob(logprob=-0.3755280077457428, rank=1, decoded_token='\\n\\n\\n\\n\\n\\nname')}, {29918: Logprob(logprob=-0.0005237876321189106, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n_')}, {29955: Logprob(logprob=-2.1367220878601074, rank=3, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n7'), 29953: Logprob(logprob=-2.1054720878601074, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n6')}, {29946: Logprob(logprob=-2.3930678367614746, rank=6, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n4'), 29896: Logprob(logprob=-2.2368178367614746, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n1')}, {313: Logprob(logprob=-0.0012511529494076967, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n (')}, {983: Logprob(logprob=-11.944221496582031, rank=3308, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nica'), 1256: Logprob(logprob=-3.170783758163452, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ndate')}, {29877: Logprob(logprob=-0.08102887123823166, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\no')}, {21748: Logprob(logprob=-0.6854418516159058, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n VARCHAR')}, {29892: Logprob(logprob=-0.005799727980047464, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n,')}, {4799: Logprob(logprob=-2.178102493286133, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n air')}, {637: Logprob(logprob=-1.936806321144104, rank=2, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nport'), 1220: Logprob(logprob=-0.2414938360452652, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nline')}, {21748: Logprob(logprob=-0.4293473958969116, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n VARCHAR')}, {29897: Logprob(logprob=-0.1584867238998413, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n)')}, {13: Logprob(logprob=-0.002474462613463402, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')}, {13: Logprob(logprob=-0.00011824862303910777, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')}, {1139: Logprob(logprob=-7.73638384998776e-05, rank=1, decoded_token=' question')}, {29901: Logprob(logprob=-0.00013219437096267939, rank=1, decoded_token='\\n:')}, {4408: Logprob(logprob=-2.1940650939941406, rank=3, decoded_token='\\n\\n Name'), 1724: Logprob(logprob=-0.6471899747848511, rank=1, decoded_token='\\n\\n What')}, {278: Logprob(logprob=-0.21818111836910248, rank=1, decoded_token='\\n\\n\\n the')}, {306: Logprob(logprob=-0.9201486110687256, rank=2, decoded_token='\\n\\n\\n\\n I'), 29871: Logprob(logprob=-0.8810861110687256, rank=1, decoded_token='\\n\\n\\n\\n ')}, {5454: Logprob(logprob=-0.07014685124158859, rank=1, decoded_token='\\n\\n\\n\\n\\nCA')}, {29949: Logprob(logprob=-0.0022903657518327236, rank=1, decoded_token='\\n\\n\\n\\n\\n\\nO')}, {363: Logprob(logprob=-1.1083241701126099, rank=2, decoded_token='\\n\\n\\n\\n\\n\\n\\n for'), 310: Logprob(logprob=-1.1005116701126099, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n of')}, {301: Logprob(logprob=-6.23159122467041, rank=51, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n l'), 278: Logprob(logprob=-1.204247236251831, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n the')}, {309: Logprob(logprob=-4.745607376098633, rank=20, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\nil'), 898: Logprob(logprob=-2.136232376098633, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\nond')}, {549: Logprob(logprob=-0.7052613496780396, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nong')}, {705: Logprob(logprob=-0.002821514382958412, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nwe')}, {6121: Logprob(logprob=-1.5109386444091797, rank=2, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n international'), 4799: Logprob(logprob=-1.2375011444091797, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n air')}, {4799: Logprob(logprob=-0.1420583575963974, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n air')}, {637: Logprob(logprob=-0.0024986020289361477, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nport')}, {29871: Logprob(logprob=-0.4706132113933563, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n ')}, {32001: Logprob(logprob=-0.0058407350443303585, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[/user]')}, {259: Logprob(logprob=-0.0001110968878492713, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  ')}, {32002: Logprob(logprob=-0.0002335037279408425, rank=1, decoded_token='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[assistant]')}], outputs=[CompletionOutput(index=0, text=\"  SELECT icao FROM table_name_74 WHERE airport = 'lilongwe international airport' \", token_ids=[29871, 5097, 474, 1113, 29877, 3895, 1591, 29918, 978, 29918, 29955, 29946, 5754, 4799, 637, 353, 525, 29880, 309, 549, 705, 6121, 4799, 637, 29915, 29871, 32003], cumulative_logprob=-1.4553729911585833, logprobs=[{29871: Logprob(logprob=-1.6093124941107817e-05, rank=1, decoded_token=' ')}, {5097: Logprob(logprob=-0.0011726891389116645, rank=1, decoded_token=' SELECT')}, {474: Logprob(logprob=-1.0733246803283691, rank=1, decoded_token=' i')}, {1113: Logprob(logprob=-0.08642563223838806, rank=1, decoded_token='ca')}, {29877: Logprob(logprob=-1.3470558769768104e-05, rank=1, decoded_token='o')}, {3895: Logprob(logprob=-0.006228559650480747, rank=1, decoded_token=' FROM')}, {1591: Logprob(logprob=-0.000809699238743633, rank=1, decoded_token=' table')}, {29918: Logprob(logprob=-1.311301275563892e-06, rank=1, decoded_token='_')}, {978: Logprob(logprob=-9.142934868577868e-05, rank=1, decoded_token='name')}, {29918: Logprob(logprob=-6.437280717364047e-06, rank=1, decoded_token='_')}, {29955: Logprob(logprob=-0.0001380348257953301, rank=1, decoded_token='7')}, {29946: Logprob(logprob=-8.67805938469246e-05, rank=1, decoded_token='4')}, {5754: Logprob(logprob=-0.0008445986895821989, rank=1, decoded_token=' WHERE')}, {4799: Logprob(logprob=-0.004095857031643391, rank=1, decoded_token=' air')}, {637: Logprob(logprob=-4.184158387943171e-05, rank=1, decoded_token='port')}, {353: Logprob(logprob=-0.003189360024407506, rank=1, decoded_token=' =')}, {525: Logprob(logprob=-0.0027813343331217766, rank=1, decoded_token=\" '\")}, {29880: Logprob(logprob=-0.19405284523963928, rank=1, decoded_token='l')}, {309: Logprob(logprob=-0.00033384948619641364, rank=1, decoded_token='il')}, {549: Logprob(logprob=-4.8874615458771586e-05, rank=1, decoded_token='ong')}, {705: Logprob(logprob=-0.00039593485416844487, rank=1, decoded_token='we')}, {6121: Logprob(logprob=-0.00318068522028625, rank=1, decoded_token=' international')}, {4799: Logprob(logprob=-0.07165645807981491, rank=1, decoded_token=' air')}, {637: Logprob(logprob=-9.97731985989958e-05, rank=1, decoded_token='port')}, {29915: Logprob(logprob=-0.005014936905354261, rank=1, decoded_token=\"'\")}, {29871: Logprob(logprob=-0.0005701346672140062, rank=1, decoded_token=' ')}, {32003: Logprob(logprob=-0.0007516896002925932, rank=1, decoded_token='[/assistant]')}], finish_reason=stop, stop_reason=32003)], finished=True, metrics=RequestMetrics(arrival_time=1717989123.429678, last_token_time=1717989124.9463942, first_scheduled_time=1717989124.2487378, first_token_time=1717989124.3423002, time_in_queue=0.8190598487854004, finished_time=1717989124.946392), lora_request=LoRARequest(lora_name='sql-lora2', lora_int_id=2, lora_local_path='/home/harpreet_guest2/.cache/huggingface/hub/models--yard1--llama-2-7b-sql-lora-test/snapshots/0dfa347e8877a4d4ed19ee56c140fa518470028c', long_lora_max_len=None))\n",
      "RequestOutput(request_id=0, prompt='A robot may not injure a human being', prompt_token_ids=[1, 319, 19964, 1122, 451, 10899, 545, 263, 5199, 1641], prompt_logprobs=[None, {319: Logprob(logprob=-4.5557684898376465, rank=8, decoded_token='A'), 917: Logprob(logprob=-2.5245184898376465, rank=1, decoded_token='Tags')}, {19964: Logprob(logprob=-8.996478080749512, rank=1474, decoded_token='robot'), 716: Logprob(logprob=-3.735247850418091, rank=1, decoded_token='new')}, {1122: Logprob(logprob=-4.979100227355957, rank=22, decoded_token='may'), 293: Logprob(logprob=-1.4712878465652466, rank=1, decoded_token='ic')}, {451: Logprob(logprob=-2.097038745880127, rank=2, decoded_token='not'), 367: Logprob(logprob=-1.3626636266708374, rank=1, decoded_token='be')}, {10899: Logprob(logprob=-0.5526919960975647, rank=1, decoded_token='inj')}, {545: Logprob(logprob=-0.0006244616815820336, rank=1, decoded_token='ure')}, {263: Logprob(logprob=-0.027345167472958565, rank=1, decoded_token='a')}, {5199: Logprob(logprob=-0.016767755150794983, rank=1, decoded_token='human')}, {1641: Logprob(logprob=-0.06561322510242462, rank=1, decoded_token='being')}], outputs=[CompletionOutput(index=0, text=' or, through inaction, allow a human being to come to harm.\\nA robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\\nA robot must protect its own existence as long as such protection does not conflict with the First or Second Law.\\nThe Three Laws of Robotics were created by Isaac Asimov in 1942. They are the foundation of robotics and artificial intelligence.\\nThe Three Laws of Robotics are the foundation of robotics and artificial intelligence. They were created by Isaac Asimov in 194', token_ids=[470, 29892, 1549, 297, 2467, 29892, 2758, 263, 5199, 1641, 304, 2041, 304, 10311, 29889, 13, 29909, 19964, 1818, 26449, 278, 11299, 2183, 372, 491, 5199, 367, 886, 5174, 988, 1316, 11299, 723, 14529, 411, 278, 3824, 7927, 29889, 13, 29909, 19964, 1818, 12566, 967, 1914, 10379, 408, 1472, 408, 1316, 13047, 947, 451, 14529, 411, 278, 3824, 470, 6440, 7927, 29889, 13, 1576, 12753, 997, 5652, 310, 6417, 327, 1199, 892, 2825, 491, 28156, 1094, 326, 586, 297, 29871, 29896, 29929, 29946, 29906, 29889, 2688, 526, 278, 22778, 310, 19964, 1199, 322, 23116, 21082, 29889, 13, 1576, 12753, 997, 5652, 310, 6417, 327, 1199, 526, 278, 22778, 310, 19964, 1199, 322, 23116, 21082, 29889, 2688, 892, 2825, 491, 28156, 1094, 326, 586, 297, 29871, 29896, 29929, 29946], cumulative_logprob=-42.50470037915284, logprobs=[{470: Logprob(logprob=-0.7071324586868286, rank=1, decoded_token=' or')}, {29892: Logprob(logprob=-0.069645956158638, rank=1, decoded_token=',')}, {1549: Logprob(logprob=-0.05649522319436073, rank=1, decoded_token=' through')}, {297: Logprob(logprob=-0.0066216811537742615, rank=1, decoded_token=' in')}, {2467: Logprob(logprob=-0.002476722002029419, rank=1, decoded_token='action')}, {29892: Logprob(logprob=-0.009543274529278278, rank=1, decoded_token=',')}, {2758: Logprob(logprob=-0.012967661023139954, rank=1, decoded_token=' allow')}, {263: Logprob(logprob=-0.0036897454410791397, rank=1, decoded_token=' a')}, {5199: Logprob(logprob=-0.01502858567982912, rank=1, decoded_token=' human')}, {1641: Logprob(logprob=-0.019629623740911484, rank=1, decoded_token=' being')}, {304: Logprob(logprob=-0.005351266358047724, rank=1, decoded_token=' to')}, {2041: Logprob(logprob=-0.002556985942646861, rank=1, decoded_token=' come')}, {304: Logprob(logprob=-0.004206856247037649, rank=1, decoded_token=' to')}, {10311: Logprob(logprob=-0.019782740622758865, rank=1, decoded_token=' harm')}, {29889: Logprob(logprob=-0.32701340317726135, rank=1, decoded_token='.')}, {13: Logprob(logprob=-0.7431644201278687, rank=1, decoded_token='\\n')}, {29909: Logprob(logprob=-1.040076732635498, rank=1, decoded_token='A')}, {19964: Logprob(logprob=-0.009812336415052414, rank=1, decoded_token=' robot')}, {1818: Logprob(logprob=-0.06792448461055756, rank=1, decoded_token=' must')}, {26449: Logprob(logprob=-0.10188902169466019, rank=1, decoded_token=' obey')}, {278: Logprob(logprob=-0.680310845375061, rank=1, decoded_token=' the')}, {11299: Logprob(logprob=-0.0066049834713339806, rank=1, decoded_token=' orders')}, {2183: Logprob(logprob=-0.0027852572966367006, rank=1, decoded_token=' given')}, {372: Logprob(logprob=-0.41315948963165283, rank=1, decoded_token=' it')}, {491: Logprob(logprob=-0.01426052674651146, rank=1, decoded_token=' by')}, {5199: Logprob(logprob=-0.02044379524886608, rank=1, decoded_token=' human')}, {367: Logprob(logprob=-0.06255031377077103, rank=1, decoded_token=' be')}, {886: Logprob(logprob=-1.7762025890988298e-05, rank=1, decoded_token='ings')}, {5174: Logprob(logprob=-0.38704806566238403, rank=1, decoded_token=' except')}, {988: Logprob(logprob=-0.00916382111608982, rank=1, decoded_token=' where')}, {1316: Logprob(logprob=-0.00024399164249189198, rank=1, decoded_token=' such')}, {11299: Logprob(logprob=-0.009193114936351776, rank=1, decoded_token=' orders')}, {723: Logprob(logprob=-0.0037435467820614576, rank=1, decoded_token=' would')}, {14529: Logprob(logprob=-0.0011526852613314986, rank=1, decoded_token=' conflict')}, {411: Logprob(logprob=-0.0015174552099779248, rank=1, decoded_token=' with')}, {278: Logprob(logprob=-0.013080621138215065, rank=1, decoded_token=' the')}, {3824: Logprob(logprob=-0.05747849866747856, rank=1, decoded_token=' First')}, {7927: Logprob(logprob=-0.05685049667954445, rank=1, decoded_token=' Law')}, {29889: Logprob(logprob=-0.06233349069952965, rank=1, decoded_token='.')}, {13: Logprob(logprob=-0.023846136406064034, rank=1, decoded_token='\\n')}, {29909: Logprob(logprob=-0.35320401191711426, rank=1, decoded_token='A')}, {19964: Logprob(logprob=-0.004396653734147549, rank=1, decoded_token=' robot')}, {1818: Logprob(logprob=-0.03311610221862793, rank=1, decoded_token=' must')}, {12566: Logprob(logprob=-0.005632363725453615, rank=1, decoded_token=' protect')}, {967: Logprob(logprob=-0.002730690874159336, rank=1, decoded_token=' its')}, {1914: Logprob(logprob=-0.005268024746328592, rank=1, decoded_token=' own')}, {10379: Logprob(logprob=-0.0012657972984015942, rank=1, decoded_token=' existence')}, {408: Logprob(logprob=-0.009128266014158726, rank=1, decoded_token=' as')}, {1472: Logprob(logprob=-6.246371776796877e-05, rank=1, decoded_token=' long')}, {408: Logprob(logprob=-0.0010413468116894364, rank=1, decoded_token=' as')}, {1316: Logprob(logprob=-0.00041952868923544884, rank=1, decoded_token=' such')}, {13047: Logprob(logprob=-0.0010632582707330585, rank=1, decoded_token=' protection')}, {947: Logprob(logprob=-0.002183436183258891, rank=1, decoded_token=' does')}, {451: Logprob(logprob=-0.001073380233719945, rank=1, decoded_token=' not')}, {14529: Logprob(logprob=-0.00650881789624691, rank=1, decoded_token=' conflict')}, {411: Logprob(logprob=-0.0007049936102703214, rank=1, decoded_token=' with')}, {278: Logprob(logprob=-0.007756353821605444, rank=1, decoded_token=' the')}, {3824: Logprob(logprob=-0.0033049744088202715, rank=1, decoded_token=' First')}, {470: Logprob(logprob=-0.011249212548136711, rank=1, decoded_token=' or')}, {6440: Logprob(logprob=-0.004977216944098473, rank=1, decoded_token=' Second')}, {7927: Logprob(logprob=-0.07616360485553741, rank=1, decoded_token=' Law')}, {29889: Logprob(logprob=-0.05263770744204521, rank=1, decoded_token='.')}, {13: Logprob(logprob=-0.05268894135951996, rank=1, decoded_token='\\n')}, {1576: Logprob(logprob=-1.9777884483337402, rank=1, decoded_token='The')}, {12753: Logprob(logprob=-1.7783585786819458, rank=1, decoded_token=' Three')}, {997: Logprob(logprob=-0.01592160388827324, rank=1, decoded_token=' La')}, {5652: Logprob(logprob=-1.2397689715726301e-05, rank=1, decoded_token='ws')}, {310: Logprob(logprob=-0.4606998562812805, rank=1, decoded_token=' of')}, {6417: Logprob(logprob=-0.025900932028889656, rank=1, decoded_token=' Rob')}, {327: Logprob(logprob=-0.015208474360406399, rank=1, decoded_token='ot')}, {1199: Logprob(logprob=-0.0006367324967868626, rank=1, decoded_token='ics')}, {892: Logprob(logprob=-1.1412835121154785, rank=1, decoded_token=' were')}, {2825: Logprob(logprob=-1.8209367990493774, rank=1, decoded_token=' created')}, {491: Logprob(logprob=-0.25607261061668396, rank=1, decoded_token=' by')}, {28156: Logprob(logprob=-0.7896146774291992, rank=1, decoded_token=' Isaac')}, {1094: Logprob(logprob=-0.003042475553229451, rank=1, decoded_token=' As')}, {326: Logprob(logprob=-0.001693958998657763, rank=1, decoded_token='im')}, {586: Logprob(logprob=-0.0005211663665249944, rank=1, decoded_token='ov')}, {297: Logprob(logprob=-0.7622541785240173, rank=1, decoded_token=' in')}, {29871: Logprob(logprob=-0.7568538188934326, rank=1, decoded_token=' ')}, {29896: Logprob(logprob=-0.0010700459824874997, rank=1, decoded_token='1')}, {29929: Logprob(logprob=-0.0001821352052502334, rank=1, decoded_token='9')}, {29946: Logprob(logprob=-0.012007927522063255, rank=1, decoded_token='4')}, {29906: Logprob(logprob=-0.02180740423500538, rank=1, decoded_token='2')}, {29889: Logprob(logprob=-1.1053558588027954, rank=1, decoded_token='.')}, {2688: Logprob(logprob=-1.4157524108886719, rank=1, decoded_token=' They')}, {526: Logprob(logprob=-1.2132138013839722, rank=1, decoded_token=' are')}, {278: Logprob(logprob=-1.6289736032485962, rank=1, decoded_token=' the')}, {22778: Logprob(logprob=-1.7325941324234009, rank=1, decoded_token=' foundation')}, {310: Logprob(logprob=-0.4009532928466797, rank=1, decoded_token=' of')}, {19964: Logprob(logprob=-1.2213786840438843, rank=1, decoded_token=' robot')}, {1199: Logprob(logprob=-0.8891727328300476, rank=1, decoded_token='ics')}, {322: Logprob(logprob=-1.3660712242126465, rank=1, decoded_token=' and')}, {23116: Logprob(logprob=-1.497464656829834, rank=1, decoded_token=' artificial')}, {21082: Logprob(logprob=-0.011571550741791725, rank=1, decoded_token=' intelligence')}, {29889: Logprob(logprob=-0.9353020191192627, rank=1, decoded_token='.')}, {13: Logprob(logprob=-1.278910517692566, rank=1, decoded_token='\\n')}, {1576: Logprob(logprob=-1.4276809692382812, rank=1, decoded_token='The')}, {12753: Logprob(logprob=-1.3494826555252075, rank=1, decoded_token=' Three')}, {997: Logprob(logprob=-0.008658249862492085, rank=1, decoded_token=' La')}, {5652: Logprob(logprob=-5.483612312673358e-06, rank=1, decoded_token='ws')}, {310: Logprob(logprob=-0.7687768936157227, rank=1, decoded_token=' of')}, {6417: Logprob(logprob=-0.020309820771217346, rank=1, decoded_token=' Rob')}, {327: Logprob(logprob=-0.0012700833613052964, rank=1, decoded_token='ot')}, {1199: Logprob(logprob=-0.00043478095903992653, rank=1, decoded_token='ics')}, {526: Logprob(logprob=-1.20071280002594, rank=1, decoded_token=' are')}, {278: Logprob(logprob=-2.023000955581665, rank=1, decoded_token=' the')}, {22778: Logprob(logprob=-1.634056806564331, rank=1, decoded_token=' foundation')}, {310: Logprob(logprob=-0.21071232855319977, rank=1, decoded_token=' of')}, {19964: Logprob(logprob=-0.42544370889663696, rank=1, decoded_token=' robot')}, {1199: Logprob(logprob=-0.22649210691452026, rank=1, decoded_token='ics')}, {322: Logprob(logprob=-0.18017353117465973, rank=1, decoded_token=' and')}, {23116: Logprob(logprob=-0.17624905705451965, rank=1, decoded_token=' artificial')}, {21082: Logprob(logprob=-0.008818845264613628, rank=1, decoded_token=' intelligence')}, {29889: Logprob(logprob=-0.23728562891483307, rank=1, decoded_token='.')}, {2688: Logprob(logprob=-0.8601693511009216, rank=1, decoded_token=' They')}, {892: Logprob(logprob=-0.7502342462539673, rank=1, decoded_token=' were')}, {2825: Logprob(logprob=-0.40748801827430725, rank=1, decoded_token=' created')}, {491: Logprob(logprob=-0.08251480013132095, rank=1, decoded_token=' by')}, {28156: Logprob(logprob=-0.08947350829839706, rank=1, decoded_token=' Isaac')}, {1094: Logprob(logprob=-0.0008559139096178114, rank=1, decoded_token=' As')}, {326: Logprob(logprob=-0.00047267231275327504, rank=1, decoded_token='im')}, {586: Logprob(logprob=-0.0002300474588992074, rank=1, decoded_token='ov')}, {297: Logprob(logprob=-0.08691272884607315, rank=1, decoded_token=' in')}, {29871: Logprob(logprob=-0.09982194006443024, rank=1, decoded_token=' ')}, {29896: Logprob(logprob=-0.00013279033009894192, rank=1, decoded_token='1')}, {29929: Logprob(logprob=-6.19869097135961e-05, rank=1, decoded_token='9')}, {29946: Logprob(logprob=-0.0008142255246639252, rank=1, decoded_token='4')}], finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717989123.1926732, last_token_time=1717989126.577229, first_scheduled_time=1717989123.196179, first_token_time=1717989123.2203588, time_in_queue=0.003505706787109375, finished_time=1717989126.577219), lora_request=None)\n",
      "RequestOutput(request_id=1, prompt='To be or not to be,', prompt_token_ids=[1, 1763, 367, 470, 451, 304, 367, 29892], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' that is the question.\\nI am not sure what I would do if I had to make a decision to live or die.\\nI would probably die, just to be sure.\\nI think I would die, because if I were to live, I would not be able to live.\\nIf I were dead, I could live, but I would not be happy.\\nIf I had to choose between living and dying, I think that I would choose to live, but if I were dead, it would be a terrible choice.\\nI would choose to live and die.\\nI don’t know what my choice would', token_ids=[393, 338, 278, 1139, 29889, 13, 29902, 626, 451, 1854, 825, 306, 723, 437, 565, 306, 750, 304, 1207, 263, 10608, 304, 5735, 470, 762, 29889, 13, 29902, 723, 3117, 762, 29892, 925, 304, 367, 1854, 29889, 13, 29902, 1348, 306, 723, 762, 29892, 1363, 565, 306, 892, 304, 5735, 29892, 306, 723, 451, 367, 2221, 304, 5735, 29889, 13, 3644, 306, 892, 7123, 29892, 306, 1033, 5735, 29892, 541, 306, 723, 451, 367, 9796, 29889, 13, 3644, 306, 750, 304, 6755, 1546, 8471, 322, 27116, 29892, 306, 1348, 393, 306, 723, 6755, 304, 5735, 29892, 541, 565, 306, 892, 7123, 29892, 372, 723, 367, 263, 16403, 7348, 29889, 13, 29902, 723, 6755, 304, 5735, 322, 762, 29889, 13, 29902, 1016, 30010, 29873, 1073, 825, 590, 7348, 723], cumulative_logprob=-117.33431613110952, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717989123.220733, last_token_time=1717989126.577229, first_scheduled_time=1717989123.2209327, first_token_time=1717989123.2749603, time_in_queue=0.00019979476928710938, finished_time=1717989126.5772266), lora_request=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_requests(engine: LLMEngine,\n",
    "                     test_prompts: List[Tuple[str, SamplingParams,\n",
    "                                              Optional[LoRARequest]]]):\n",
    "    \"\"\"Continuously process a list of prompts and handle the outputs.\"\"\"\n",
    "    request_id = 0\n",
    "\n",
    "    while test_prompts or engine.has_unfinished_requests():\n",
    "        if test_prompts:\n",
    "            prompt, sampling_params, lora_request = test_prompts.pop(0)\n",
    "            engine.add_request(str(request_id),\n",
    "                               prompt,\n",
    "                               sampling_params,\n",
    "                               lora_request=lora_request)\n",
    "            request_id += 1\n",
    "\n",
    "        request_outputs: List[RequestOutput] = engine.step()\n",
    "\n",
    "        for request_output in request_outputs:\n",
    "            if request_output.finished:\n",
    "                print(request_output)\n",
    "    return request_outputs\n",
    "\n",
    "\n",
    "def initialize_engine() -> LLMEngine:\n",
    "    \"\"\"Initialize the LLMEngine.\"\"\"\n",
    "    # max_loras: controls the number of LoRAs that can be used in the same\n",
    "    #   batch. Larger numbers will cause higher memory usage, as each LoRA\n",
    "    #   slot requires its own preallocated tensor.\n",
    "    # max_lora_rank: controls the maximum supported rank of all LoRAs. Larger\n",
    "    #   numbers will cause higher memory usage. If you know that all LoRAs will\n",
    "    #   use the same rank, it is recommended to set this as low as possible.\n",
    "    # max_cpu_loras: controls the size of the CPU LoRA cache.\n",
    "    engine_args = EngineArgs(model=\"meta-llama/Llama-2-7b-hf\",\n",
    "                             enable_lora=True,\n",
    "                             max_loras=1,\n",
    "                             max_lora_rank=8,\n",
    "                             max_cpu_loras=2,\n",
    "                             max_num_seqs=256)\n",
    "    return LLMEngine.from_engine_args(engine_args)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function that sets up and runs the prompt processing.\"\"\"\n",
    "    engine = initialize_engine()\n",
    "    lora_path = snapshot_download(repo_id=\"yard1/llama-2-7b-sql-lora-test\")\n",
    "    test_prompts = create_test_prompts(lora_path)\n",
    "    return process_requests(engine, test_prompts)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    result = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RequestOutput(request_id=0, prompt='A robot may not injure a human being', prompt_token_ids=[1, 319, 19964, 1122, 451, 10899, 545, 263, 5199, 1641], prompt_logprobs=[None, {319: Logprob(logprob=-4.5557684898376465, rank=8, decoded_token='A'), 917: Logprob(logprob=-2.5245184898376465, rank=1, decoded_token='Tags')}, {19964: Logprob(logprob=-8.996478080749512, rank=1474, decoded_token='robot'), 716: Logprob(logprob=-3.735247850418091, rank=1, decoded_token='new')}, {1122: Logprob(logprob=-4.979100227355957, rank=22, decoded_token='may'), 293: Logprob(logprob=-1.4712878465652466, rank=1, decoded_token='ic')}, {451: Logprob(logprob=-2.097038745880127, rank=2, decoded_token='not'), 367: Logprob(logprob=-1.3626636266708374, rank=1, decoded_token='be')}, {10899: Logprob(logprob=-0.5526919960975647, rank=1, decoded_token='inj')}, {545: Logprob(logprob=-0.0006244616815820336, rank=1, decoded_token='ure')}, {263: Logprob(logprob=-0.027345167472958565, rank=1, decoded_token='a')}, {5199: Logprob(logprob=-0.016767755150794983, rank=1, decoded_token='human')}, {1641: Logprob(logprob=-0.06561322510242462, rank=1, decoded_token='being')}], outputs=[CompletionOutput(index=0, text=' or, through inaction, allow a human being to come to harm.\\nA robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\\nA robot must protect its own existence as long as such protection does not conflict with the First or Second Law.\\nThe Three Laws of Robotics were created by Isaac Asimov in 1942. They are the foundation of robotics and artificial intelligence.\\nThe Three Laws of Robotics are the foundation of robotics and artificial intelligence. They were created by Isaac Asimov in 194', token_ids=[470, 29892, 1549, 297, 2467, 29892, 2758, 263, 5199, 1641, 304, 2041, 304, 10311, 29889, 13, 29909, 19964, 1818, 26449, 278, 11299, 2183, 372, 491, 5199, 367, 886, 5174, 988, 1316, 11299, 723, 14529, 411, 278, 3824, 7927, 29889, 13, 29909, 19964, 1818, 12566, 967, 1914, 10379, 408, 1472, 408, 1316, 13047, 947, 451, 14529, 411, 278, 3824, 470, 6440, 7927, 29889, 13, 1576, 12753, 997, 5652, 310, 6417, 327, 1199, 892, 2825, 491, 28156, 1094, 326, 586, 297, 29871, 29896, 29929, 29946, 29906, 29889, 2688, 526, 278, 22778, 310, 19964, 1199, 322, 23116, 21082, 29889, 13, 1576, 12753, 997, 5652, 310, 6417, 327, 1199, 526, 278, 22778, 310, 19964, 1199, 322, 23116, 21082, 29889, 2688, 892, 2825, 491, 28156, 1094, 326, 586, 297, 29871, 29896, 29929, 29946], cumulative_logprob=-42.50470037915284, logprobs=[{470: Logprob(logprob=-0.7071324586868286, rank=1, decoded_token=' or')}, {29892: Logprob(logprob=-0.069645956158638, rank=1, decoded_token=',')}, {1549: Logprob(logprob=-0.05649522319436073, rank=1, decoded_token=' through')}, {297: Logprob(logprob=-0.0066216811537742615, rank=1, decoded_token=' in')}, {2467: Logprob(logprob=-0.002476722002029419, rank=1, decoded_token='action')}, {29892: Logprob(logprob=-0.009543274529278278, rank=1, decoded_token=',')}, {2758: Logprob(logprob=-0.012967661023139954, rank=1, decoded_token=' allow')}, {263: Logprob(logprob=-0.0036897454410791397, rank=1, decoded_token=' a')}, {5199: Logprob(logprob=-0.01502858567982912, rank=1, decoded_token=' human')}, {1641: Logprob(logprob=-0.019629623740911484, rank=1, decoded_token=' being')}, {304: Logprob(logprob=-0.005351266358047724, rank=1, decoded_token=' to')}, {2041: Logprob(logprob=-0.002556985942646861, rank=1, decoded_token=' come')}, {304: Logprob(logprob=-0.004206856247037649, rank=1, decoded_token=' to')}, {10311: Logprob(logprob=-0.019782740622758865, rank=1, decoded_token=' harm')}, {29889: Logprob(logprob=-0.32701340317726135, rank=1, decoded_token='.')}, {13: Logprob(logprob=-0.7431644201278687, rank=1, decoded_token='\\n')}, {29909: Logprob(logprob=-1.040076732635498, rank=1, decoded_token='A')}, {19964: Logprob(logprob=-0.009812336415052414, rank=1, decoded_token=' robot')}, {1818: Logprob(logprob=-0.06792448461055756, rank=1, decoded_token=' must')}, {26449: Logprob(logprob=-0.10188902169466019, rank=1, decoded_token=' obey')}, {278: Logprob(logprob=-0.680310845375061, rank=1, decoded_token=' the')}, {11299: Logprob(logprob=-0.0066049834713339806, rank=1, decoded_token=' orders')}, {2183: Logprob(logprob=-0.0027852572966367006, rank=1, decoded_token=' given')}, {372: Logprob(logprob=-0.41315948963165283, rank=1, decoded_token=' it')}, {491: Logprob(logprob=-0.01426052674651146, rank=1, decoded_token=' by')}, {5199: Logprob(logprob=-0.02044379524886608, rank=1, decoded_token=' human')}, {367: Logprob(logprob=-0.06255031377077103, rank=1, decoded_token=' be')}, {886: Logprob(logprob=-1.7762025890988298e-05, rank=1, decoded_token='ings')}, {5174: Logprob(logprob=-0.38704806566238403, rank=1, decoded_token=' except')}, {988: Logprob(logprob=-0.00916382111608982, rank=1, decoded_token=' where')}, {1316: Logprob(logprob=-0.00024399164249189198, rank=1, decoded_token=' such')}, {11299: Logprob(logprob=-0.009193114936351776, rank=1, decoded_token=' orders')}, {723: Logprob(logprob=-0.0037435467820614576, rank=1, decoded_token=' would')}, {14529: Logprob(logprob=-0.0011526852613314986, rank=1, decoded_token=' conflict')}, {411: Logprob(logprob=-0.0015174552099779248, rank=1, decoded_token=' with')}, {278: Logprob(logprob=-0.013080621138215065, rank=1, decoded_token=' the')}, {3824: Logprob(logprob=-0.05747849866747856, rank=1, decoded_token=' First')}, {7927: Logprob(logprob=-0.05685049667954445, rank=1, decoded_token=' Law')}, {29889: Logprob(logprob=-0.06233349069952965, rank=1, decoded_token='.')}, {13: Logprob(logprob=-0.023846136406064034, rank=1, decoded_token='\\n')}, {29909: Logprob(logprob=-0.35320401191711426, rank=1, decoded_token='A')}, {19964: Logprob(logprob=-0.004396653734147549, rank=1, decoded_token=' robot')}, {1818: Logprob(logprob=-0.03311610221862793, rank=1, decoded_token=' must')}, {12566: Logprob(logprob=-0.005632363725453615, rank=1, decoded_token=' protect')}, {967: Logprob(logprob=-0.002730690874159336, rank=1, decoded_token=' its')}, {1914: Logprob(logprob=-0.005268024746328592, rank=1, decoded_token=' own')}, {10379: Logprob(logprob=-0.0012657972984015942, rank=1, decoded_token=' existence')}, {408: Logprob(logprob=-0.009128266014158726, rank=1, decoded_token=' as')}, {1472: Logprob(logprob=-6.246371776796877e-05, rank=1, decoded_token=' long')}, {408: Logprob(logprob=-0.0010413468116894364, rank=1, decoded_token=' as')}, {1316: Logprob(logprob=-0.00041952868923544884, rank=1, decoded_token=' such')}, {13047: Logprob(logprob=-0.0010632582707330585, rank=1, decoded_token=' protection')}, {947: Logprob(logprob=-0.002183436183258891, rank=1, decoded_token=' does')}, {451: Logprob(logprob=-0.001073380233719945, rank=1, decoded_token=' not')}, {14529: Logprob(logprob=-0.00650881789624691, rank=1, decoded_token=' conflict')}, {411: Logprob(logprob=-0.0007049936102703214, rank=1, decoded_token=' with')}, {278: Logprob(logprob=-0.007756353821605444, rank=1, decoded_token=' the')}, {3824: Logprob(logprob=-0.0033049744088202715, rank=1, decoded_token=' First')}, {470: Logprob(logprob=-0.011249212548136711, rank=1, decoded_token=' or')}, {6440: Logprob(logprob=-0.004977216944098473, rank=1, decoded_token=' Second')}, {7927: Logprob(logprob=-0.07616360485553741, rank=1, decoded_token=' Law')}, {29889: Logprob(logprob=-0.05263770744204521, rank=1, decoded_token='.')}, {13: Logprob(logprob=-0.05268894135951996, rank=1, decoded_token='\\n')}, {1576: Logprob(logprob=-1.9777884483337402, rank=1, decoded_token='The')}, {12753: Logprob(logprob=-1.7783585786819458, rank=1, decoded_token=' Three')}, {997: Logprob(logprob=-0.01592160388827324, rank=1, decoded_token=' La')}, {5652: Logprob(logprob=-1.2397689715726301e-05, rank=1, decoded_token='ws')}, {310: Logprob(logprob=-0.4606998562812805, rank=1, decoded_token=' of')}, {6417: Logprob(logprob=-0.025900932028889656, rank=1, decoded_token=' Rob')}, {327: Logprob(logprob=-0.015208474360406399, rank=1, decoded_token='ot')}, {1199: Logprob(logprob=-0.0006367324967868626, rank=1, decoded_token='ics')}, {892: Logprob(logprob=-1.1412835121154785, rank=1, decoded_token=' were')}, {2825: Logprob(logprob=-1.8209367990493774, rank=1, decoded_token=' created')}, {491: Logprob(logprob=-0.25607261061668396, rank=1, decoded_token=' by')}, {28156: Logprob(logprob=-0.7896146774291992, rank=1, decoded_token=' Isaac')}, {1094: Logprob(logprob=-0.003042475553229451, rank=1, decoded_token=' As')}, {326: Logprob(logprob=-0.001693958998657763, rank=1, decoded_token='im')}, {586: Logprob(logprob=-0.0005211663665249944, rank=1, decoded_token='ov')}, {297: Logprob(logprob=-0.7622541785240173, rank=1, decoded_token=' in')}, {29871: Logprob(logprob=-0.7568538188934326, rank=1, decoded_token=' ')}, {29896: Logprob(logprob=-0.0010700459824874997, rank=1, decoded_token='1')}, {29929: Logprob(logprob=-0.0001821352052502334, rank=1, decoded_token='9')}, {29946: Logprob(logprob=-0.012007927522063255, rank=1, decoded_token='4')}, {29906: Logprob(logprob=-0.02180740423500538, rank=1, decoded_token='2')}, {29889: Logprob(logprob=-1.1053558588027954, rank=1, decoded_token='.')}, {2688: Logprob(logprob=-1.4157524108886719, rank=1, decoded_token=' They')}, {526: Logprob(logprob=-1.2132138013839722, rank=1, decoded_token=' are')}, {278: Logprob(logprob=-1.6289736032485962, rank=1, decoded_token=' the')}, {22778: Logprob(logprob=-1.7325941324234009, rank=1, decoded_token=' foundation')}, {310: Logprob(logprob=-0.4009532928466797, rank=1, decoded_token=' of')}, {19964: Logprob(logprob=-1.2213786840438843, rank=1, decoded_token=' robot')}, {1199: Logprob(logprob=-0.8891727328300476, rank=1, decoded_token='ics')}, {322: Logprob(logprob=-1.3660712242126465, rank=1, decoded_token=' and')}, {23116: Logprob(logprob=-1.497464656829834, rank=1, decoded_token=' artificial')}, {21082: Logprob(logprob=-0.011571550741791725, rank=1, decoded_token=' intelligence')}, {29889: Logprob(logprob=-0.9353020191192627, rank=1, decoded_token='.')}, {13: Logprob(logprob=-1.278910517692566, rank=1, decoded_token='\\n')}, {1576: Logprob(logprob=-1.4276809692382812, rank=1, decoded_token='The')}, {12753: Logprob(logprob=-1.3494826555252075, rank=1, decoded_token=' Three')}, {997: Logprob(logprob=-0.008658249862492085, rank=1, decoded_token=' La')}, {5652: Logprob(logprob=-5.483612312673358e-06, rank=1, decoded_token='ws')}, {310: Logprob(logprob=-0.7687768936157227, rank=1, decoded_token=' of')}, {6417: Logprob(logprob=-0.020309820771217346, rank=1, decoded_token=' Rob')}, {327: Logprob(logprob=-0.0012700833613052964, rank=1, decoded_token='ot')}, {1199: Logprob(logprob=-0.00043478095903992653, rank=1, decoded_token='ics')}, {526: Logprob(logprob=-1.20071280002594, rank=1, decoded_token=' are')}, {278: Logprob(logprob=-2.023000955581665, rank=1, decoded_token=' the')}, {22778: Logprob(logprob=-1.634056806564331, rank=1, decoded_token=' foundation')}, {310: Logprob(logprob=-0.21071232855319977, rank=1, decoded_token=' of')}, {19964: Logprob(logprob=-0.42544370889663696, rank=1, decoded_token=' robot')}, {1199: Logprob(logprob=-0.22649210691452026, rank=1, decoded_token='ics')}, {322: Logprob(logprob=-0.18017353117465973, rank=1, decoded_token=' and')}, {23116: Logprob(logprob=-0.17624905705451965, rank=1, decoded_token=' artificial')}, {21082: Logprob(logprob=-0.008818845264613628, rank=1, decoded_token=' intelligence')}, {29889: Logprob(logprob=-0.23728562891483307, rank=1, decoded_token='.')}, {2688: Logprob(logprob=-0.8601693511009216, rank=1, decoded_token=' They')}, {892: Logprob(logprob=-0.7502342462539673, rank=1, decoded_token=' were')}, {2825: Logprob(logprob=-0.40748801827430725, rank=1, decoded_token=' created')}, {491: Logprob(logprob=-0.08251480013132095, rank=1, decoded_token=' by')}, {28156: Logprob(logprob=-0.08947350829839706, rank=1, decoded_token=' Isaac')}, {1094: Logprob(logprob=-0.0008559139096178114, rank=1, decoded_token=' As')}, {326: Logprob(logprob=-0.00047267231275327504, rank=1, decoded_token='im')}, {586: Logprob(logprob=-0.0002300474588992074, rank=1, decoded_token='ov')}, {297: Logprob(logprob=-0.08691272884607315, rank=1, decoded_token=' in')}, {29871: Logprob(logprob=-0.09982194006443024, rank=1, decoded_token=' ')}, {29896: Logprob(logprob=-0.00013279033009894192, rank=1, decoded_token='1')}, {29929: Logprob(logprob=-6.19869097135961e-05, rank=1, decoded_token='9')}, {29946: Logprob(logprob=-0.0008142255246639252, rank=1, decoded_token='4')}], finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717989123.1926732, last_token_time=1717989126.577229, first_scheduled_time=1717989123.196179, first_token_time=1717989123.2203588, time_in_queue=0.003505706787109375, finished_time=1717989126.577219), lora_request=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
